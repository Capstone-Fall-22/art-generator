{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical devices cannot be modified after being initialized\n"
     ]
    }
   ],
   "source": [
    "# Prepare gpu for training\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "tf.config.list_physical_devices(\"GPU\")\n",
    "\n",
    "\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 12800)             652800    \n",
      "                                                                 \n",
      " reshape_4 (Reshape)         (None, 5, 5, 512)         0         \n",
      "                                                                 \n",
      " re_lu_20 (ReLU)             (None, 5, 5, 512)         0         \n",
      "                                                                 \n",
      " batch_normalization_35 (Bat  (None, 5, 5, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_27 (Conv2D  (None, 10, 10, 512)      2359808   \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_36 (Bat  (None, 10, 10, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_28 (Conv2D  (None, 20, 20, 256)      1179904   \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_37 (Bat  (None, 20, 20, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_29 (Conv2D  (None, 40, 40, 128)      295040    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_38 (Bat  (None, 40, 40, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_30 (Conv2D  (None, 80, 80, 64)       73792     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_39 (Bat  (None, 80, 80, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_31 (Conv2D  (None, 160, 160, 64)     36928     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_40 (Bat  (None, 160, 160, 64)     256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_32 (Conv2D  (None, 320, 320, 64)     36928     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_41 (Bat  (None, 320, 320, 64)     256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_33 (Conv2D  (None, 640, 640, 32)     18464     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_42 (Bat  (None, 640, 640, 32)     128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_21 (ReLU)             (None, 640, 640, 32)      0         \n",
      "                                                                 \n",
      " batch_normalization_43 (Bat  (None, 640, 640, 32)     128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " resizing_4 (Resizing)       (None, 360, 640, 32)      0         \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 360, 640, 3)       867       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,661,187\n",
      "Trainable params: 4,657,859\n",
      "Non-trainable params: 3,328\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_17 (Conv2D)          (None, 180, 320, 64)      1792      \n",
      "                                                                 \n",
      " re_lu_22 (ReLU)             (None, 180, 320, 64)      0         \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 180, 320, 64)      0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 90, 160, 128)      73856     \n",
      "                                                                 \n",
      " re_lu_23 (ReLU)             (None, 90, 160, 128)      0         \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 90, 160, 128)      0         \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 45, 80, 256)       295168    \n",
      "                                                                 \n",
      " re_lu_24 (ReLU)             (None, 45, 80, 256)       0         \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 45, 80, 256)       0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 921600)            0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 921601    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,292,417\n",
      "Trainable params: 1,292,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from scripts.model.build import get_architecture\n",
    "from scripts.experiment import load_config\n",
    "\n",
    "config = load_config(\"dcgan_mini_scapes\", \"model\")\n",
    "\n",
    "gen_summary, disc_summary = get_architecture(config)\n",
    "\n",
    "print(gen_summary)\n",
    "\n",
    "print(disc_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.experiment import run_experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for previous batch #0: Generator loss = None, Discriminator loss = None\n",
      "Epoch # 1/1\n",
      "Batch # 1\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Exception encountered when calling layer 'batch_normalization_44' (type BatchNormalization).\n\n{{function_node __wrapped__FusedBatchNormV3_device_/job:localhost/replica:0/task:0/device:GPU:0}} cuDNN launch failure : input shape ([1,5,5,512]) [Op:FusedBatchNormV3]\n\nCall arguments received by layer 'batch_normalization_44' (type BatchNormalization):\n  • inputs=tf.Tensor(shape=(1, 5, 5, 512), dtype=float16)\n  • training=True\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m generator, discriminator \u001b[39m=\u001b[39m run_experiment(\u001b[39m\"\u001b[39;49m\u001b[39mmini_scapes_resized\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mdcgan_mini_scapes\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mdcgan_mini_scapes_v1\u001b[39;49m\u001b[39m\"\u001b[39;49m, num_examples_to_generate\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, colab\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/big_bertha/coding/capstone/art-generator/experiments/scripts/experiment.py:39\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(dataset_name, model_name, experiment_name, num_examples_to_generate, epochs, colab)\u001b[0m\n\u001b[1;32m     22\u001b[0m gen_optimizer, disc_optimizer \u001b[39m=\u001b[39m load_optimizers(model_config)\n\u001b[1;32m     24\u001b[0m train_config \u001b[39m=\u001b[39m {\n\u001b[1;32m     25\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m\"\u001b[39m: epochs,\n\u001b[1;32m     26\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_dir\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mresults\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcolab\u001b[39m\u001b[39m\"\u001b[39m: colab\n\u001b[1;32m     37\u001b[0m }\n\u001b[0;32m---> 39\u001b[0m train(train_config)\n\u001b[1;32m     41\u001b[0m \u001b[39mreturn\u001b[39;00m generator, discriminator\n",
      "File \u001b[0;32m~/big_bertha/coding/capstone/art-generator/experiments/scripts/model/train.py:81\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mBatch # \u001b[39m\u001b[39m{\u001b[39;00mi \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     80\u001b[0m     gc\u001b[39m.\u001b[39mcollect()\n\u001b[0;32m---> 81\u001b[0m     gen_loss, disc_loss \u001b[39m=\u001b[39m train_step(config, batch)\n\u001b[1;32m     83\u001b[0m generate_and_save_images(config[\u001b[39m\"\u001b[39m\u001b[39mgenerator\u001b[39m\u001b[39m\"\u001b[39m], epoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, test_seeds, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(output_dir, config[\u001b[39m\"\u001b[39m\u001b[39mexperiment_name\u001b[39m\u001b[39m\"\u001b[39m]))\n\u001b[1;32m     84\u001b[0m config[\u001b[39m\"\u001b[39m\u001b[39mgenerator\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39msave(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(output_dir, config[\u001b[39m\"\u001b[39m\u001b[39mexperiment_name\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgenerator_epoch_\u001b[39m\u001b[39m{\u001b[39;00mepoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/big_bertha/coding/capstone/art-generator/experiments/scripts/model/train.py:38\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(config, real_image_batch)\u001b[0m\n\u001b[1;32m     35\u001b[0m input_noise_seeds \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mnormal([config[\u001b[39m'\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m'\u001b[39m], config[\u001b[39m'\u001b[39m\u001b[39mlen_seed\u001b[39m\u001b[39m'\u001b[39m]])\n\u001b[1;32m     37\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m gen_tape, tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m disc_tape:\n\u001b[0;32m---> 38\u001b[0m     generated_image_batch \u001b[39m=\u001b[39m config[\u001b[39m\"\u001b[39m\u001b[39mgenerator\u001b[39m\u001b[39m\"\u001b[39m](input_noise_seeds, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     40\u001b[0m     y_pred_real \u001b[39m=\u001b[39m config[\u001b[39m\"\u001b[39m\u001b[39mdiscriminator\u001b[39m\u001b[39m\"\u001b[39m](real_image_batch, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     41\u001b[0m     y_pred_fake \u001b[39m=\u001b[39m config[\u001b[39m\"\u001b[39m\u001b[39mdiscriminator\u001b[39m\u001b[39m\"\u001b[39m](generated_image_batch, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "\u001b[0;31mInternalError\u001b[0m: Exception encountered when calling layer 'batch_normalization_44' (type BatchNormalization).\n\n{{function_node __wrapped__FusedBatchNormV3_device_/job:localhost/replica:0/task:0/device:GPU:0}} cuDNN launch failure : input shape ([1,5,5,512]) [Op:FusedBatchNormV3]\n\nCall arguments received by layer 'batch_normalization_44' (type BatchNormalization):\n  • inputs=tf.Tensor(shape=(1, 5, 5, 512), dtype=float16)\n  • training=True\n  • mask=None"
     ]
    }
   ],
   "source": [
    "generator, discriminator = run_experiment(\"mini_scapes_resized\", \"dcgan_mini_scapes\", \"dcgan_mini_scapes_v1\", num_examples_to_generate=4, epochs=1, colab=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save experiment results to google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "!cp -r /content/results/dcgan_mini_scapes_v1 /content/gdrive/experiments/dcgan_mini_scapes_v1\n",
    "\n",
    "drive.flush_and_unmount()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b1c19a084cb33ef0f2d488bfb5bf89f4e55dc917e237e1f0ec816b469d1d4ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
