{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-16 21:20:58.872085: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-16 21:20:58.951283: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-16 21:20:59.385417: W tensorflow/tsl/platform/default/dso_loader.cc:66] Could not load dynamic library 'libnvinfer.so.8'; dlerror: libnvinfer.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/chen/miniconda3/lib/:/home/chen/miniconda3/envs/tf/lib/\n",
      "2022-11-16 21:20:59.385673: W tensorflow/tsl/platform/default/dso_loader.cc:66] Could not load dynamic library 'libnvinfer_plugin.so.8'; dlerror: libnvinfer_plugin.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/chen/miniconda3/lib/:/home/chen/miniconda3/envs/tf/lib/\n",
      "2022-11-16 21:20:59.385678: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n",
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3070, compute capability 8.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-16 21:20:59.859829: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2022-11-16 21:20:59.864864: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2022-11-16 21:20:59.865003: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2022-11-16 21:20:59.865956: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2022-11-16 21:20:59.866053: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2022-11-16 21:20:59.866119: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2022-11-16 21:21:00.206933: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2022-11-16 21:21:00.207046: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2022-11-16 21:21:00.207118: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2022-11-16 21:21:00.207181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1614] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4852 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-11-16 21:21:00.208604: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "# Prepare gpu for training\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "tf.config.list_physical_devices(\"GPU\")\n",
    "\n",
    "\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 25600)             2585600   \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 5, 5, 1024)        0         \n",
      "                                                                 \n",
      " re_lu_10 (ReLU)             (None, 5, 5, 1024)        0         \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 5, 5, 1024)       4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " up_sampling2d_16 (UpSamplin  (None, 10, 10, 1024)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 10, 10, 1024)      9438208   \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 10, 10, 1024)     4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " up_sampling2d_17 (UpSamplin  (None, 20, 20, 1024)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 20, 20, 512)       4719104   \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 20, 20, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " up_sampling2d_18 (UpSamplin  (None, 40, 40, 512)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 40, 40, 256)       1179904   \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 40, 40, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " up_sampling2d_19 (UpSamplin  (None, 80, 80, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 80, 80, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 80, 80, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " up_sampling2d_20 (UpSamplin  (None, 160, 160, 256)    0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 160, 160, 128)     295040    \n",
      "                                                                 \n",
      " batch_normalization_23 (Bat  (None, 160, 160, 128)    512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " up_sampling2d_21 (UpSamplin  (None, 320, 320, 128)    0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 320, 320, 128)     147584    \n",
      "                                                                 \n",
      " batch_normalization_24 (Bat  (None, 320, 320, 128)    512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " up_sampling2d_22 (UpSamplin  (None, 640, 640, 128)    0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 640, 640, 64)      73792     \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 640, 640, 64)     256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " up_sampling2d_23 (UpSamplin  (None, 1280, 1280, 64)   0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 1280, 1280, 64)    36928     \n",
      "                                                                 \n",
      " batch_normalization_26 (Bat  (None, 1280, 1280, 64)   256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " resizing_2 (Resizing)       (None, 720, 1280, 64)     0         \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 720, 1280, 3)      1731      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,081,795\n",
      "Trainable params: 19,074,883\n",
      "Non-trainable params: 6,912\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_35 (Conv2D)          (None, 360, 640, 64)      1792      \n",
      "                                                                 \n",
      " re_lu_11 (ReLU)             (None, 360, 640, 64)      0         \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 360, 640, 64)      0         \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          (None, 180, 320, 128)     73856     \n",
      "                                                                 \n",
      " re_lu_12 (ReLU)             (None, 180, 320, 128)     0         \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 180, 320, 128)     0         \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 90, 160, 256)      295168    \n",
      "                                                                 \n",
      " re_lu_13 (ReLU)             (None, 90, 160, 256)      0         \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 90, 160, 256)      0         \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 45, 80, 512)       1180160   \n",
      "                                                                 \n",
      " re_lu_14 (ReLU)             (None, 45, 80, 512)       0         \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 45, 80, 512)       0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 1843200)           0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 1843201   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,394,177\n",
      "Trainable params: 3,394,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from scripts.model.build import get_architecture\n",
    "from scripts.experiment import load_config\n",
    "\n",
    "config = load_config(\"dcgan_scapes_16m\", \"model\")\n",
    "\n",
    "gen_summary, disc_summary = get_architecture(config)\n",
    "\n",
    "print(gen_summary)\n",
    "\n",
    "print(disc_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for previous batch #0: Generator loss = None, Discriminator loss = None\n",
      "Epoch # 1/1\n",
      "Batch # 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-15 10:29:50.298961: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:421] Loaded runtime CuDNN library: 8.1.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2022-11-15 10:29:50.299387: W ./tensorflow/compiler/xla/stream_executor/stream.h:1553] attempting to perform DNN operation using StreamExecutor without DNN support\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential/batch_normalization/FusedBatchNormV3' defined at (most recent call last):\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 982, in launch_instance\n      app.start()\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_29362/209267532.py\", line 2, in <module>\n      generator, discriminator = run_experiment(\"mini_scapes_resized\", \"dcgan_mini_scapes\", \"dcgan_mini_scapes_v1\", num_examples_to_generate=4, epochs=1, colab=False)\n    File \"/home/chen/big_bertha/coding/capstone/art-generator/experiments/scripts/experiment.py\", line 39, in run_experiment\n      train(train_config)\n    File \"/home/chen/big_bertha/coding/capstone/art-generator/experiments/scripts/model/train.py\", line 83, in train\n      gen_loss, disc_loss = train_step(config, batch)\n    File \"/home/chen/big_bertha/coding/capstone/art-generator/experiments/scripts/model/train.py\", line 38, in train_step\n      generated_image_batch = config[\"generator\"](input_noise_seeds, training=True)\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 559, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/sequential.py\", line 413, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/layers/normalization/batch_normalization.py\", line 922, in call\n      outputs = self._fused_batch_norm(\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/layers/normalization/batch_normalization.py\", line 688, in _fused_batch_norm\n      output, mean, variance = control_flow_util.smart_cond(\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/control_flow_util.py\", line 108, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/layers/normalization/batch_normalization.py\", line 662, in _fused_batch_norm_training\n      return tf.compat.v1.nn.fused_batch_norm(\nNode: 'sequential/batch_normalization/FusedBatchNormV3'\ncuDNN launch failure : input shape ([2,512,5,5])\n\t [[{{node sequential/batch_normalization/FusedBatchNormV3}}]] [Op:__inference_train_step_1414]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscripts\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperiment\u001b[39;00m \u001b[39mimport\u001b[39;00m run_experiment\n\u001b[0;32m----> 2\u001b[0m generator, discriminator \u001b[39m=\u001b[39m run_experiment(\u001b[39m\"\u001b[39;49m\u001b[39mmini_scapes_resized\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mdcgan_mini_scapes\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mdcgan_mini_scapes_v1\u001b[39;49m\u001b[39m\"\u001b[39;49m, num_examples_to_generate\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, colab\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/big_bertha/coding/capstone/art-generator/experiments/scripts/experiment.py:39\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(dataset_name, model_name, experiment_name, num_examples_to_generate, epochs, colab)\u001b[0m\n\u001b[1;32m     22\u001b[0m gen_optimizer, disc_optimizer \u001b[39m=\u001b[39m load_optimizers(model_config)\n\u001b[1;32m     24\u001b[0m train_config \u001b[39m=\u001b[39m {\n\u001b[1;32m     25\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m\"\u001b[39m: epochs,\n\u001b[1;32m     26\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_dir\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mresults\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcolab\u001b[39m\u001b[39m\"\u001b[39m: colab\n\u001b[1;32m     37\u001b[0m }\n\u001b[0;32m---> 39\u001b[0m train(train_config)\n\u001b[1;32m     41\u001b[0m \u001b[39mreturn\u001b[39;00m generator, discriminator\n",
      "File \u001b[0;32m~/big_bertha/coding/capstone/art-generator/experiments/scripts/model/train.py:83\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mBatch # \u001b[39m\u001b[39m{\u001b[39;00mi \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     82\u001b[0m     gc\u001b[39m.\u001b[39mcollect()\n\u001b[0;32m---> 83\u001b[0m     gen_loss, disc_loss \u001b[39m=\u001b[39m train_step(config, batch)\n\u001b[1;32m     85\u001b[0m generate_and_save_images(config[\u001b[39m\"\u001b[39m\u001b[39mgenerator\u001b[39m\u001b[39m\"\u001b[39m], epoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, test_seeds, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(output_dir, config[\u001b[39m\"\u001b[39m\u001b[39mexperiment_name\u001b[39m\u001b[39m\"\u001b[39m]))\n\u001b[1;32m     86\u001b[0m config[\u001b[39m\"\u001b[39m\u001b[39mgenerator\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39msave(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(output_dir, config[\u001b[39m\"\u001b[39m\u001b[39mexperiment_name\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgenerator_epoch_\u001b[39m\u001b[39m{\u001b[39;00mepoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInternalError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential/batch_normalization/FusedBatchNormV3' defined at (most recent call last):\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 982, in launch_instance\n      app.start()\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_29362/209267532.py\", line 2, in <module>\n      generator, discriminator = run_experiment(\"mini_scapes_resized\", \"dcgan_mini_scapes\", \"dcgan_mini_scapes_v1\", num_examples_to_generate=4, epochs=1, colab=False)\n    File \"/home/chen/big_bertha/coding/capstone/art-generator/experiments/scripts/experiment.py\", line 39, in run_experiment\n      train(train_config)\n    File \"/home/chen/big_bertha/coding/capstone/art-generator/experiments/scripts/model/train.py\", line 83, in train\n      gen_loss, disc_loss = train_step(config, batch)\n    File \"/home/chen/big_bertha/coding/capstone/art-generator/experiments/scripts/model/train.py\", line 38, in train_step\n      generated_image_batch = config[\"generator\"](input_noise_seeds, training=True)\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 559, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/sequential.py\", line 413, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/layers/normalization/batch_normalization.py\", line 922, in call\n      outputs = self._fused_batch_norm(\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/layers/normalization/batch_normalization.py\", line 688, in _fused_batch_norm\n      output, mean, variance = control_flow_util.smart_cond(\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/control_flow_util.py\", line 108, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/layers/normalization/batch_normalization.py\", line 662, in _fused_batch_norm_training\n      return tf.compat.v1.nn.fused_batch_norm(\nNode: 'sequential/batch_normalization/FusedBatchNormV3'\ncuDNN launch failure : input shape ([2,512,5,5])\n\t [[{{node sequential/batch_normalization/FusedBatchNormV3}}]] [Op:__inference_train_step_1414]"
     ]
    }
   ],
   "source": [
    "from scripts.experiment import run_experiment\n",
    "generator, discriminator = run_experiment(\"mini_scapes_resized\", \"dcgan_mini_scapes\", \"dcgan_mini_scapes_v1\", num_examples_to_generate=4, epochs=1, colab=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save experiment results to google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "!cp -r /content/results/dcgan_mini_scapes_v1 /content/gdrive/experiments/dcgan_mini_scapes_v1\n",
    "\n",
    "drive.flush_and_unmount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# load model with tf keras\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "generator = load_model(\"/home/chen/big_bertha/coding/capstone/art-generator/experiments/models/generator_epoch_10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chen/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Exception encountered when calling layer 'batch_normalization_20' (type BatchNormalization).\n\n{{function_node __wrapped__FusedBatchNormV3_device_/job:localhost/replica:0/task:0/device:GPU:0}} cuDNN launch failure : input shape ([1,5,5,512]) [Op:FusedBatchNormV3]\n\nCall arguments received by layer 'batch_normalization_20' (type BatchNormalization):\n  • inputs=tf.Tensor(shape=(1, 5, 5, 512), dtype=float16)\n  • training=False\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m generator\u001b[39m.\u001b[39;49mpredict(tf\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mnormal([\u001b[39m1\u001b[39;49m, \u001b[39m100\u001b[39;49m]))\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:7215\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7214\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 7215\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mInternalError\u001b[0m: Exception encountered when calling layer 'batch_normalization_20' (type BatchNormalization).\n\n{{function_node __wrapped__FusedBatchNormV3_device_/job:localhost/replica:0/task:0/device:GPU:0}} cuDNN launch failure : input shape ([1,5,5,512]) [Op:FusedBatchNormV3]\n\nCall arguments received by layer 'batch_normalization_20' (type BatchNormalization):\n  • inputs=tf.Tensor(shape=(1, 5, 5, 512), dtype=float16)\n  • training=False\n  • mask=None"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b1c19a084cb33ef0f2d488bfb5bf89f4e55dc917e237e1f0ec816b469d1d4ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
